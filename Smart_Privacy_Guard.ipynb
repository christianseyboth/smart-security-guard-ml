{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO+ybpBOV24Atcimi9R8gbO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/christianseyboth/smart-security-guard-ml/blob/main/Smart_Privacy_Guard.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2y_dsf4RMeMU",
        "outputId": "5234ece5-b69c-4d80-ee26-17ca0b13e437"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "üéØ Smart Privacy Guard - ML Projekt gestartet!\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# ==================================================================================\n",
        "# SMART PRIVACY GUARD - Dein erstes ML-Projekt! üöÄ\n",
        "# ==================================================================================\n",
        "#\n",
        "# ZIEL: Baue einen Text-Klassifizierer, der sensible Daten erkennt\n",
        "# ZEIT: 1-2 Wochen, aber schon heute erste Ergebnisse!\n",
        "#\n",
        "# SETUP: Kopiere diesen Code in Google Colab und arbeite dich durch die TODOs!\n",
        "# Link: https://colab.research.google.com\n",
        "#\n",
        "# ==================================================================================\n",
        "\n",
        "# TEIL 1: SETUP & DATEN\n",
        "# ==================================================================================\n",
        "\n",
        "# Installations-Command f√ºr Colab\n",
        "!pip install scikit-learn pandas numpy matplotlib seaborn\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "import re\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"üéØ Smart Privacy Guard - ML Projekt gestartet!\")\n",
        "print(\"=\" * 50)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  DATEN SAMMELN (Deine erste wichtige Aufgabe!)"
      ],
      "metadata": {
        "id": "rfsEZR7_Rnne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================================================\n",
        "# TEIL 2: DATEN SAMMELN (Deine erste wichtige Aufgabe!)\n",
        "# ==================================================================================\n",
        "\n",
        "def create_training_dataset():\n",
        "    \"\"\"\n",
        "    TODO F√úR DICH: Erweitere diese Datens√§tze!\n",
        "    Je mehr realistische Beispiele, desto besser dein Modell!\n",
        "    \"\"\"\n",
        "\n",
        "    # Sensible Texte - erweitere diese Liste!\n",
        "    sensitive_texts = [\n",
        "        # Email-Adressen\n",
        "        \"Meine Email ist max.mustermann@gmail.com\",\n",
        "        \"Kontakt unter: info@firma.de\",\n",
        "        \"Schreib mir an: test.user@web.de\",\n",
        "\n",
        "        # Telefonnummern\n",
        "        \"Meine Nummer: +49 30 12345678\",\n",
        "        \"Tel: 0171-9876543 f√ºr R√ºckfragen\",\n",
        "        \"Handy: +49 151 23456789\",\n",
        "\n",
        "        # Finanzielle Daten\n",
        "        \"IBAN: DE89 3704 0044 0532 0130 00\",\n",
        "        \"Kreditkarte: 4111 1111 1111 1111\",\n",
        "        \"Kontostand: 2.500‚Ç¨ auf Konto DE123456789\",\n",
        "\n",
        "        # Passw√∂rter & Credentials\n",
        "        \"Mein Passwort ist SuperSecret123!\",\n",
        "        \"Login: user123, Password: mypass456\",\n",
        "        \"API-Key: sk-1234567890abcdef\",\n",
        "        \"Hier mein SSH-Key: -----BEGIN RSA PRIVATE KEY----- ‚Ä¶\"\n",
        "\n",
        "        # Adressen\n",
        "        \"Ich wohne in der Hauptstra√üe 123, 10115 Berlin\",\n",
        "        \"Adresse: Musterweg 45, 20095 Hamburg\",\n",
        "        \"PLZ 80331 M√ºnchen, Tal 5\",\n",
        "\n",
        "        # Pers√∂nliche Daten\n",
        "        \"Geburtsdatum: 15.03.1985\",\n",
        "        \"Ausweisnummer: T22000123456\",\n",
        "        \"Steuer-ID: 12 345 678 901\",\n",
        "    ]\n",
        "\n",
        "    # Harmlose Texte - erweitere auch diese!\n",
        "    harmless_texts = [\n",
        "        # Allt√§gliche Gespr√§che\n",
        "        \"Wie geht es dir heute?\",\n",
        "        \"Das Wetter ist wirklich sch√∂n!\",\n",
        "        \"Hast du Lust auf Kaffee sp√§ter?\",\n",
        "        \"Der Film gestern war interessant\",\n",
        "\n",
        "        # Arbeit & Technik\n",
        "        \"Das Meeting ist um 14 Uhr\",\n",
        "        \"Ich programmiere gerne in Python\",\n",
        "        \"Machine Learning ist faszinierend\",\n",
        "        \"Die neue Software funktioniert gut\",\n",
        "\n",
        "        # Hobbys & Interessen\n",
        "        \"Ich koche gerne italienisch\",\n",
        "        \"Sport ist wichtig f√ºr die Gesundheit\",\n",
        "        \"B√ºcher lesen entspannt mich\",\n",
        "        \"Musik h√∂ren macht Spa√ü\",\n",
        "\n",
        "        # Allgemeine Aussagen\n",
        "        \"Heute ist ein sch√∂ner Tag\",\n",
        "        \"Lernen macht Freude\",\n",
        "        \"Teamwork ist wichtig\",\n",
        "        \"Kreativit√§t ist wertvoll\",\n",
        "        \"Mach mir eine\",\n",
        "        \"Ich brauche eine\",\n",
        "        \"Erstelle mir\"\n",
        "    ]\n",
        "\n",
        "    # TODO F√úR DICH: F√ºge hier mindestens 10 weitere Beispiele hinzu!\n",
        "    # Tipp: Denk an edge cases - was k√∂nnte dein Modell verwirren?\n",
        "\n",
        "    # Daten kombinieren\n",
        "    all_texts = sensitive_texts + harmless_texts\n",
        "    all_labels = ['sensitive'] * len(sensitive_texts) + ['harmless'] * len(harmless_texts)\n",
        "\n",
        "    # DataFrame erstellen\n",
        "    df = pd.DataFrame({\n",
        "        'text': all_texts,\n",
        "        'label': all_labels\n",
        "    })\n",
        "\n",
        "    print(f\"üìä Datensatz erstellt:\")\n",
        "    print(f\"   - {len(sensitive_texts)} sensible Texte\")\n",
        "    print(f\"   - {len(harmless_texts)} harmlose Texte\")\n",
        "    print(f\"   - Total: {len(df)} Trainingsbeispiele\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# Daten laden\n",
        "df = create_training_dataset()\n",
        "print(df.head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pS2bDXxXMoHG",
        "outputId": "9b27ceb5-0fba-4ff5-ca43-e107733501a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Datensatz erstellt:\n",
            "   - 18 sensible Texte\n",
            "   - 19 harmlose Texte\n",
            "   - Total: 37 Trainingsbeispiele\n",
            "                                       text      label\n",
            "0  Meine Email ist max.mustermann@gmail.com  sensitive\n",
            "1              Kontakt unter: info@firma.de  sensitive\n",
            "2          Schreib mir an: test.user@web.de  sensitive\n",
            "3             Meine Nummer: +49 30 12345678  sensitive\n",
            "4          Tel: 0171-9876543 f√ºr R√ºckfragen  sensitive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FEATURE ENGINEERING (Das Herzst√ºck!)"
      ],
      "metadata": {
        "id": "1-itMei-Sc-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================================================\n",
        "# TEIL 3: FEATURE ENGINEERING (Das Herzst√ºck!)\n",
        "# ==================================================================================\n",
        "\n",
        "class CustomFeatureExtractor:\n",
        "    \"\"\"\n",
        "    Deine Features aus dem JavaScript-Playground - jetzt in Python!\n",
        "    TODO: Erweitere diese Features f√ºr bessere Erkennung!\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.feature_names = [\n",
        "            'has_email', 'has_phone', 'has_iban', 'has_credit_card',\n",
        "            'text_length', 'word_count', 'digit_ratio', 'special_char_ratio',\n",
        "            'sensitive_keyword_count', 'has_at_symbol', 'has_plus_sign'\n",
        "        ]\n",
        "\n",
        "    def extract_features(self, text):\n",
        "        \"\"\"\n",
        "        TODO F√úR DICH: F√ºge weitere Features hinzu!\n",
        "        Welche Patterns k√∂nnten noch wichtig sein?\n",
        "        \"\"\"\n",
        "        features = []\n",
        "        text_lower = text.lower()\n",
        "\n",
        "        # Pattern-basierte Features\n",
        "        features.append(1 if '@' in text and '.' in text else 0)  # Email\n",
        "        features.append(1 if re.search(r'\\+?\\d{2,}[\\s\\-\\(\\)]?\\d{3,}', text) else 0)  # Phone\n",
        "        features.append(1 if re.search(r'[a-z]{2}\\d{2}', text_lower) else 0)  # IBAN\n",
        "        features.append(1 if re.search(r'\\d{4}[\\s\\-]?\\d{4}[\\s\\-]?\\d{4}[\\s\\-]?\\d{4}', text) else 0)  # Credit Card\n",
        "\n",
        "        # Text-Eigenschaften\n",
        "        features.append(len(text))  # L√§nge\n",
        "        features.append(len(text.split()))  # Wortanzahl\n",
        "        features.append(len(re.findall(r'\\d', text)) / max(len(text), 1))  # Digit-Ratio\n",
        "        features.append(len(re.findall(r'[^\\w\\s]', text)) / max(len(text), 1))  # Special char ratio\n",
        "\n",
        "        # Keyword-Features\n",
        "        sensitive_words = ['passwort', 'password', 'iban', 'kreditkarte', 'pin', 'cvv']\n",
        "        keyword_count = sum(1 for word in sensitive_words if word in text_lower)\n",
        "        features.append(keyword_count)\n",
        "\n",
        "        # Symbol-Features\n",
        "        features.append(1 if '@' in text else 0)\n",
        "        features.append(1 if '+' in text else 0)\n",
        "\n",
        "        return features\n",
        "\n",
        "    def fit_transform(self, texts):\n",
        "        \"\"\"Alle Texte zu Features umwandeln\"\"\"\n",
        "        return np.array([self.extract_features(text) for text in texts])\n",
        "\n",
        "# Feature Extractor erstellen\n",
        "feature_extractor = CustomFeatureExtractor()\n",
        "\n"
      ],
      "metadata": {
        "id": "G2ImZfo4R8cU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL TRAINING (Hier passiert die Magie!)"
      ],
      "metadata": {
        "id": "4cDhRNeZSspb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================================================\n",
        "# TEIL 4: MODEL TRAINING (Hier passiert die Magie!)\n",
        "# ==================================================================================\n",
        "\n",
        "def train_smart_privacy_guard(df):\n",
        "    \"\"\"\n",
        "    Hier trainierst du dein Modell!\n",
        "    TODO: Experimentiere mit verschiedenen Modellen!\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\nü§ñ Starte Model Training...\")\n",
        "\n",
        "    # 1. Daten vorbereiten\n",
        "    X_text = df['text'].values\n",
        "    y = df['label'].values\n",
        "\n",
        "    # 2. Train/Test Split (wie in echten ML-Projekten)\n",
        "    X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
        "        X_text, y, test_size=0.3, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    print(f\"   - Training: {len(X_train_text)} Beispiele\")\n",
        "    print(f\"   - Test: {len(X_test_text)} Beispiele\")\n",
        "\n",
        "    # 3. Feature Engineering - Zwei Ans√§tze kombinieren!\n",
        "\n",
        "    # A) TF-IDF Features (automatische Wort-Analyse)\n",
        "    tfidf_vectorizer = TfidfVectorizer(max_features=500, stop_words='english')\n",
        "    X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_text)\n",
        "    X_test_tfidf = tfidf_vectorizer.transform(X_test_text)\n",
        "\n",
        "    # B) Custom Features (deine hand-crafted Features)\n",
        "    X_train_custom = feature_extractor.fit_transform(X_train_text)\n",
        "    X_test_custom = feature_extractor.fit_transform(X_test_text)\n",
        "\n",
        "    # C) Features kombinieren (das Beste aus beiden Welten!)\n",
        "    from scipy.sparse import hstack\n",
        "    X_train_combined = hstack([X_train_tfidf, X_train_custom])\n",
        "    X_test_combined = hstack([X_test_tfidf, X_test_custom])\n",
        "\n",
        "    # 4. Model Training - TODO: Probiere verschiedene Modelle!\n",
        "    models = {\n",
        "        'Logistic Regression': LogisticRegression(random_state=42),\n",
        "        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for name, model in models.items():\n",
        "        print(f\"\\nüß† Trainiere {name}...\")\n",
        "\n",
        "        # Training\n",
        "        model.fit(X_train_combined, y_train)\n",
        "\n",
        "        # Vorhersagen\n",
        "        y_pred = model.predict(X_test_combined)\n",
        "        y_pred_proba = model.predict_proba(X_test_combined)\n",
        "\n",
        "        # Evaluation\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        print(f\"   Accuracy: {accuracy:.3f} ({accuracy*100:.1f}%)\")\n",
        "\n",
        "        results[name] = {\n",
        "            'model': model,\n",
        "            'accuracy': accuracy,\n",
        "            'predictions': y_pred,\n",
        "            'probabilities': y_pred_proba\n",
        "        }\n",
        "\n",
        "    # Bestes Modell ausw√§hlen\n",
        "    best_model_name = max(results.keys(), key=lambda x: results[x]['accuracy'])\n",
        "    best_model = results[best_model_name]['model']\n",
        "\n",
        "    print(f\"\\nüèÜ Bestes Modell: {best_model_name}\")\n",
        "    print(f\"   Accuracy: {results[best_model_name]['accuracy']*100:.1f}%\")\n",
        "\n",
        "    # Detailed Report f√ºr bestes Modell\n",
        "    print(f\"\\nüìä Detailed Report f√ºr {best_model_name}:\")\n",
        "    print(classification_report(y_test, results[best_model_name]['predictions']))\n",
        "\n",
        "    return best_model, tfidf_vectorizer, feature_extractor, X_test_text, y_test\n",
        "\n",
        "# Model trainieren\n",
        "best_model, tfidf_vectorizer, feature_extractor, X_test_text, y_test = train_smart_privacy_guard(df)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUIbafivSn0t",
        "outputId": "5b3b2d0a-293a-4e70-84b1-6d5ace3203ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ü§ñ Starte Model Training...\n",
            "   - Training: 25 Beispiele\n",
            "   - Test: 12 Beispiele\n",
            "\n",
            "üß† Trainiere Logistic Regression...\n",
            "   Accuracy: 0.917 (91.7%)\n",
            "\n",
            "üß† Trainiere Random Forest...\n",
            "   Accuracy: 0.750 (75.0%)\n",
            "\n",
            "üèÜ Bestes Modell: Logistic Regression\n",
            "   Accuracy: 91.7%\n",
            "\n",
            "üìä Detailed Report f√ºr Logistic Regression:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    harmless       1.00      0.83      0.91         6\n",
            "   sensitive       0.86      1.00      0.92         6\n",
            "\n",
            "    accuracy                           0.92        12\n",
            "   macro avg       0.93      0.92      0.92        12\n",
            "weighted avg       0.93      0.92      0.92        12\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LIVE TESTING (Wie deine Extension funktionieren w√ºrde!)"
      ],
      "metadata": {
        "id": "2YiVvY_HS4ED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================================================\n",
        "# TEIL 5: LIVE TESTING (Wie deine Extension funktionieren w√ºrde!)\n",
        "# ==================================================================================\n",
        "\n",
        "def predict_text_sensitivity(text, model, tfidf_vec, feature_ext):\n",
        "    \"\"\"\n",
        "    Das ist die Funktion, die deine Browser-Extension sp√§ter aufrufen w√ºrde!\n",
        "    \"\"\"\n",
        "    # Features extrahieren (genau wie beim Training)\n",
        "    tfidf_features = tfidf_vec.transform([text])\n",
        "    custom_features = feature_ext.fit_transform([text])\n",
        "\n",
        "    # Kombinieren\n",
        "    from scipy.sparse import hstack\n",
        "    combined_features = hstack([tfidf_features, custom_features])\n",
        "\n",
        "    # Vorhersage\n",
        "    prediction = model.predict(combined_features)[0]\n",
        "    confidence = max(model.predict_proba(combined_features)[0]) * 100\n",
        "\n",
        "    return {\n",
        "        'text': text,\n",
        "        'prediction': prediction,\n",
        "        'confidence': round(confidence, 1),\n",
        "        'is_sensitive': prediction == 'sensitive',\n",
        "        'should_warn': prediction == 'sensitive' and confidence > 70\n",
        "    }\n",
        "\n"
      ],
      "metadata": {
        "id": "_5KS8SZOS2mg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LIVE DEMO (Teste dein Modell!)"
      ],
      "metadata": {
        "id": "203lly45TC8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================================================\n",
        "# TEIL 6: LIVE DEMO (Teste dein Modell!)\n",
        "# ==================================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üß™ LIVE DEMO - Teste dein Smart Privacy Guard!\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Test-Texte (wie sie in deiner Extension auftreten w√ºrden)\n",
        "test_cases = [\n",
        "    # Sollten als SENSITIVE erkannt werden\n",
        "    \"Hier ist meine Email: test@example.com\",\n",
        "    \"Meine IBAN lautet: DE89 3704 0044 0532 0130 00\",\n",
        "    \"Telefon: +49 30 12345678 f√ºr R√ºckfragen\",\n",
        "    \"Passwort: mySecret123, bitte nicht weitergeben\",\n",
        "    \"Mein API Key ist bd-fwe-232\"\n",
        "\n",
        "    # Sollten als HARMLESS erkannt werden\n",
        "    \"Ich mag Machine Learning sehr!\",\n",
        "    \"Das Wetter ist heute wirklich sch√∂n\",\n",
        "    \"Python ist eine tolle Programmiersprache\",\n",
        "    \"Wann ist unser n√§chstes Meeting?\",\n",
        "\n",
        "    # Edge Cases - hier wird es interessant!\n",
        "    \"Email Marketing ist ein spannendes Thema\",  # Enth√§lt \"Email\" aber ist harmlos\n",
        "    \"Ich arbeite bei der Deutschen Bank\",        # Enth√§lt \"Bank\" aber ist harmlos\n",
        "    \"API Integration mit REST endpoints\"         # Technisch, aber harmlos\n",
        "]\n",
        "\n",
        "print(\"\\nüìù Teste verschiedene Texte:\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "for text in test_cases:\n",
        "    result = predict_text_sensitivity(text, best_model, tfidf_vectorizer, feature_extractor)\n",
        "\n",
        "    # Farbige Ausgabe f√ºr bessere √úbersicht\n",
        "    status_emoji = \"üö®\" if result['is_sensitive'] else \"‚úÖ\"\n",
        "    confidence_stars = \"‚òÖ\" * (int(result['confidence']) // 20)\n",
        "\n",
        "    print(f\"\\n{status_emoji} Text: '{text[:50]}{'...' if len(text) > 50 else ''}'\")\n",
        "    print(f\"   Prediction: {result['prediction'].upper()}\")\n",
        "    print(f\"   Confidence: {result['confidence']}% {confidence_stars}\")\n",
        "\n",
        "    if result['should_warn']:\n",
        "        print(f\"   ‚ö†Ô∏è  BROWSER-EXTENSION W√úRDE WARNEN!\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pxf76hXMS_zX",
        "outputId": "94f391f0-950d-4007-8d6e-b3b69d2687fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "üß™ LIVE DEMO - Teste dein Smart Privacy Guard!\n",
            "============================================================\n",
            "\n",
            "üìù Teste verschiedene Texte:\n",
            "----------------------------------------\n",
            "\n",
            "üö® Text: 'Hier ist meine Email: test@example.com'\n",
            "   Prediction: SENSITIVE\n",
            "   Confidence: 78.9% ‚òÖ‚òÖ‚òÖ\n",
            "   ‚ö†Ô∏è  BROWSER-EXTENSION W√úRDE WARNEN!\n",
            "\n",
            "üö® Text: 'Meine IBAN lautet: DE89 3704 0044 0532 0130 00'\n",
            "   Prediction: SENSITIVE\n",
            "   Confidence: 95.2% ‚òÖ‚òÖ‚òÖ‚òÖ\n",
            "   ‚ö†Ô∏è  BROWSER-EXTENSION W√úRDE WARNEN!\n",
            "\n",
            "üö® Text: 'Telefon: +49 30 12345678 f√ºr R√ºckfragen'\n",
            "   Prediction: SENSITIVE\n",
            "   Confidence: 92.7% ‚òÖ‚òÖ‚òÖ‚òÖ\n",
            "   ‚ö†Ô∏è  BROWSER-EXTENSION W√úRDE WARNEN!\n",
            "\n",
            "üö® Text: 'Passwort: mySecret123, bitte nicht weitergeben'\n",
            "   Prediction: SENSITIVE\n",
            "   Confidence: 96.0% ‚òÖ‚òÖ‚òÖ‚òÖ\n",
            "   ‚ö†Ô∏è  BROWSER-EXTENSION W√úRDE WARNEN!\n",
            "\n",
            "üö® Text: 'Mein API Key ist bd-fwe-232Ich mag Machine Learnin...'\n",
            "   Prediction: SENSITIVE\n",
            "   Confidence: 86.6% ‚òÖ‚òÖ‚òÖ‚òÖ\n",
            "   ‚ö†Ô∏è  BROWSER-EXTENSION W√úRDE WARNEN!\n",
            "\n",
            "‚úÖ Text: 'Das Wetter ist heute wirklich sch√∂n'\n",
            "   Prediction: HARMLESS\n",
            "   Confidence: 67.8% ‚òÖ‚òÖ‚òÖ\n",
            "\n",
            "üö® Text: 'Python ist eine tolle Programmiersprache'\n",
            "   Prediction: SENSITIVE\n",
            "   Confidence: 70.8% ‚òÖ‚òÖ‚òÖ\n",
            "   ‚ö†Ô∏è  BROWSER-EXTENSION W√úRDE WARNEN!\n",
            "\n",
            "‚úÖ Text: 'Wann ist unser n√§chstes Meeting?'\n",
            "   Prediction: HARMLESS\n",
            "   Confidence: 67.7% ‚òÖ‚òÖ‚òÖ\n",
            "\n",
            "üö® Text: 'Email Marketing ist ein spannendes Thema'\n",
            "   Prediction: SENSITIVE\n",
            "   Confidence: 56.2% ‚òÖ‚òÖ\n",
            "\n",
            "‚úÖ Text: 'Ich arbeite bei der Deutschen Bank'\n",
            "   Prediction: HARMLESS\n",
            "   Confidence: 71.4% ‚òÖ‚òÖ‚òÖ\n",
            "\n",
            "‚úÖ Text: 'API Integration mit REST endpoints'\n",
            "   Prediction: HARMLESS\n",
            "   Confidence: 50.3% ‚òÖ‚òÖ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Debugging\n"
      ],
      "metadata": {
        "id": "ps7dkMqmTd7o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================================================\n",
        "# DEBUGGING HELPER (Wenn etwas nicht funktioniert)\n",
        "# ==================================================================================\n",
        "from scipy.sparse import hstack\n",
        "\n",
        "def debug_model_performance():\n",
        "    \"\"\"\n",
        "    TODO F√úR DICH: F√ºhre diese Funktion aus, wenn dein Modell schlecht performt\n",
        "    \"\"\"\n",
        "    print(\"\\nüîç Model Debugging:\")\n",
        "\n",
        "    # Zeige falsch klassifizierte Beispiele\n",
        "    X_test_combined = hstack([\n",
        "        tfidf_vectorizer.transform(X_test_text),\n",
        "        feature_extractor.fit_transform(X_test_text)\n",
        "    ])\n",
        "\n",
        "    y_pred = best_model.predict(X_test_combined)\n",
        "\n",
        "    # Finde Fehler\n",
        "    wrong_predictions = []\n",
        "    for i, (text, true_label, pred_label) in enumerate(zip(X_test_text, y_test, y_pred)):\n",
        "        if true_label != pred_label:\n",
        "            wrong_predictions.append({\n",
        "                'text': text,\n",
        "                'true': true_label,\n",
        "                'predicted': pred_label\n",
        "            })\n",
        "\n",
        "    print(f\"‚ùå {len(wrong_predictions)} falsche Vorhersagen:\")\n",
        "    for error in wrong_predictions[:3]:  # Zeige nur erste 3\n",
        "        print(f\"   Text: '{error['text']}'\")\n",
        "        print(f\"   Erwartet: {error['true']} | Vorhergesagt: {error['predicted']}\")\n",
        "        print()\n",
        "\n",
        "# F√ºhre Debugging aus\n",
        "debug_model_performance()\n",
        "\n",
        "print(\"\\nüéâ Smart Privacy Guard Projekt ist bereit!\")\n",
        "print(\"üí° N√§chster Schritt: Arbeite die TODOs durch und experimentiere!\")\n",
        "print(\"üöÄ In 1-2 Wochen hast du ein funktionierendes ML-System!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijHOVqv9Tq9g",
        "outputId": "44b7114c-0c09-47c5-b647-4bb144428ea8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîç Model Debugging:\n",
            "‚ùå 1 falsche Vorhersagen:\n",
            "   Text: 'Machine Learning ist faszinierend'\n",
            "   Erwartet: harmless | Vorhergesagt: sensitive\n",
            "\n",
            "\n",
            "üéâ Smart Privacy Guard Projekt ist bereit!\n",
            "üí° N√§chster Schritt: Arbeite die TODOs durch und experimentiere!\n",
            "üöÄ In 1-2 Wochen hast du ein funktionierendes ML-System!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aufgaben und n√§chste Schritte"
      ],
      "metadata": {
        "id": "j4MBOu1YUCre"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================================================\n",
        "# TEIL 7: DEINE AUFGABEN (Hands-on Learning!)\n",
        "# ==================================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üéØ DEINE AUFGABEN - So lernst du ML richtig!\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\"\"\n",
        "üìù AUFGABE 1 (EINFACH): Mehr Trainingsdaten\n",
        "   ‚Üí F√ºge 10 weitere sensible und 10 harmlose Texte hinzu\n",
        "   ‚Üí Trainiere das Modell neu und schau, ob die Accuracy steigt\n",
        "\n",
        "üîß AUFGABE 2 (MITTEL): Neue Features\n",
        "   ‚Üí Implementiere Features f√ºr:\n",
        "      - URLs erkennen (http://, https://)\n",
        "      - Sozialversicherungsnummern\n",
        "      - Verschiedene Sprachen (DE/EN)\n",
        "   ‚Üí Teste ob diese Features die Performance verbessern\n",
        "\n",
        "üß† AUFGABE 3 (FORTGESCHRITTEN): Model Comparison\n",
        "   ‚Üí Teste verschiedene Algorithmen:\n",
        "      - Support Vector Machine (SVM)\n",
        "      - Naive Bayes\n",
        "      - Neural Network (MLPClassifier)\n",
        "   ‚Üí Welcher funktioniert am besten f√ºr deine Daten?\n",
        "\n",
        "üöÄ AUFGABE 4 (CHALLENGE): Edge Cases\n",
        "   ‚Üí Teste dein Modell mit schwierigen F√§llen:\n",
        "      - \"Meine fake Email f√ºr Tests: test@test.com\"\n",
        "      - \"IBAN steht f√ºr International Bank Account Number\"\n",
        "      - \"Die PIN f√ºr den Tresor ist... nur ein Scherz!\"\n",
        "   ‚Üí Wie robust ist dein Modell?\n",
        "\n",
        "‚≠ê BONUS-AUFGABE (PRO): Model Saving\n",
        "   ‚Üí Speichere dein trainiertes Modell ab\n",
        "   ‚Üí Lade es wieder und nutze es f√ºr neue Vorhersagen\n",
        "   ‚Üí Das brauchst du sp√§ter f√ºr die echte Extension!\n",
        "\"\"\")\n",
        "\n",
        "# ==================================================================================\n",
        "# TEIL 8: N√ÑCHSTE SCHRITTE\n",
        "# ==================================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üöÄ ROADMAP ZU DEINER BROWSER-EXTENSION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\"\"\n",
        "WOCHE 1-2: Python ML Fundamentals (JETZT!)\n",
        "   ‚úÖ Dieses Projekt abschlie√üen\n",
        "   ‚úÖ Mit verschiedenen Algorithmen experimentieren\n",
        "   ‚úÖ Model Evaluation verstehen\n",
        "\n",
        "WOCHE 3-4: Advanced ML\n",
        "   üìö Text Preprocessing (Tokenization, Normalization)\n",
        "   üìö Cross-Validation & Hyperparameter Tuning\n",
        "   üìö Dealing mit Imbalanced Data\n",
        "\n",
        "WOCHE 5-6: Production Ready\n",
        "   üîß Model Serialization (Pickle, ONNX)\n",
        "   üîß API Development (FastAPI)\n",
        "   üîß Performance Optimization\n",
        "\n",
        "WOCHE 7-8: Browser Integration\n",
        "   üåê Chrome Extension Basics\n",
        "   üåê Python Model ‚Üí JavaScript portieren\n",
        "   üåê Real-time Text Processing\n",
        "\n",
        "ZIEL: Funktionierende Browser-Extension! üéØ\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSdOUiWHTvgN",
        "outputId": "597ee22f-b311-47ed-fe12-d218e20e7c45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "üéØ DEINE AUFGABEN - So lernst du ML richtig!\n",
            "============================================================\n",
            "\n",
            "üìù AUFGABE 1 (EINFACH): Mehr Trainingsdaten\n",
            "   ‚Üí F√ºge 10 weitere sensible und 10 harmlose Texte hinzu\n",
            "   ‚Üí Trainiere das Modell neu und schau, ob die Accuracy steigt\n",
            "   \n",
            "üîß AUFGABE 2 (MITTEL): Neue Features\n",
            "   ‚Üí Implementiere Features f√ºr:\n",
            "      - URLs erkennen (http://, https://)\n",
            "      - Sozialversicherungsnummern  \n",
            "      - Verschiedene Sprachen (DE/EN)\n",
            "   ‚Üí Teste ob diese Features die Performance verbessern\n",
            "   \n",
            "üß† AUFGABE 3 (FORTGESCHRITTEN): Model Comparison\n",
            "   ‚Üí Teste verschiedene Algorithmen:\n",
            "      - Support Vector Machine (SVM)\n",
            "      - Naive Bayes\n",
            "      - Neural Network (MLPClassifier)\n",
            "   ‚Üí Welcher funktioniert am besten f√ºr deine Daten?\n",
            "   \n",
            "üöÄ AUFGABE 4 (CHALLENGE): Edge Cases\n",
            "   ‚Üí Teste dein Modell mit schwierigen F√§llen:\n",
            "      - \"Meine fake Email f√ºr Tests: test@test.com\"\n",
            "      - \"IBAN steht f√ºr International Bank Account Number\"\n",
            "      - \"Die PIN f√ºr den Tresor ist... nur ein Scherz!\"\n",
            "   ‚Üí Wie robust ist dein Modell?\n",
            "\n",
            "‚≠ê BONUS-AUFGABE (PRO): Model Saving\n",
            "   ‚Üí Speichere dein trainiertes Modell ab\n",
            "   ‚Üí Lade es wieder und nutze es f√ºr neue Vorhersagen\n",
            "   ‚Üí Das brauchst du sp√§ter f√ºr die echte Extension!\n",
            "\n",
            "\n",
            "============================================================\n",
            "üöÄ ROADMAP ZU DEINER BROWSER-EXTENSION\n",
            "============================================================\n",
            "\n",
            "WOCHE 1-2: Python ML Fundamentals (JETZT!)\n",
            "   ‚úÖ Dieses Projekt abschlie√üen\n",
            "   ‚úÖ Mit verschiedenen Algorithmen experimentieren\n",
            "   ‚úÖ Model Evaluation verstehen\n",
            "   \n",
            "WOCHE 3-4: Advanced ML\n",
            "   üìö Text Preprocessing (Tokenization, Normalization)\n",
            "   üìö Cross-Validation & Hyperparameter Tuning\n",
            "   üìö Dealing mit Imbalanced Data\n",
            "   \n",
            "WOCHE 5-6: Production Ready\n",
            "   üîß Model Serialization (Pickle, ONNX)\n",
            "   üîß API Development (FastAPI)\n",
            "   üîß Performance Optimization\n",
            "   \n",
            "WOCHE 7-8: Browser Integration  \n",
            "   üåê Chrome Extension Basics\n",
            "   üåê Python Model ‚Üí JavaScript portieren\n",
            "   üåê Real-time Text Processing\n",
            "   \n",
            "ZIEL: Funktionierende Browser-Extension! üéØ\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hxkw_mfNULcB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}